# 创建线程的方式

> 该问题更详细的分析可以参考这篇博客: https://mp.weixin.qq.com/s/NspUsyhEmKnJ-4OprRFp9g

第一种是**继承 Thread 类**, 重写其中的 run 方法. 之后直接创建 Thread 的子类对象, 调用 start 方法. **这种方式简单易用, <font style="color:blue">但由于 Java 是单继承, 所以这种方式不够灵活</font>**



第二种方式就是**<font style="color:blue">实现 Runnable 接口</font>**, 也重写 run 方法. 然后使用 Thread 类的构造函数传入 Runnable 对象, 再调用 start 方法启动线程. **这样就可以避免单继承的限制了**



第三种方式是**实现 `Callable<V>` 接口, 重写其中的 call 方法, <font style="color:blue">之后使用 FutureTask 包装 Callable 对象</font>**, 再通过 Thread 启动. 这种方式**可以获取执行结果并且可以抛出异常**, 比 Runnable 更复杂, 适用于需要结果返回的场景

```java
public class MyCallable implements Callable<String> {
    @Override
    public String call() throws Exception {
        return "Callable executed";
    }
}

Callable<String> callable = new MyCallable();
FutureTask<String> futureTask = new FutureTask<>(callable);
Thread t = new Thread(futureTask);
t.start();

// 如果出现了异常, 就需要在调用 get() 时去显式捕获和处理
String result = futureTask.get(); // 阻塞获取结果
```



第四种方式是使用线程池, 通过 ExecutorService 提交 Runnable 或 Callable 任务, 不直接创建和管理线程, 适合管理大量的并发任务. **此外也可以通过 ThreadPoolExecutor  类来自定义线程池**

- 这种方式可以控制线程数量, 还可以复用线程, 性能比较好. **<font style="color:blue">但同时要管理线程池的生命周期</font>**



另外还可以**<font style="color:blue">使用 Java8 引入的 CompletableFuture</font>**. 它本质上就是**基于线程池来执行异步任务**的编程工具

+ **<font style="color:blue">默认使用的是 `ForkJoinPool.commonPool()` 来执行任务</font>**, 但是**也可以指定使用自定义的线程池**
+ **它可以非常方便地使用 supplyAsync 方法来启动异步任务**, 并且可以通过 thenApply、thenAccept 等方法轻松处理异步任务之间的依赖关系

# 多线程下如何避免死锁

死锁的产生有四个必要条件, **当这四个条件同时满足时就会发生死锁**

1. 互斥条件: 资源不能被多个线程同时使用. **即资源一次只能被一个线程占用**
2. 占有且等待: **<font style="color:blue">一个线程已经持有至少一把锁, 同时又在请求其它线程占用的锁</font>**, **且不释放已持有的锁**
3. **不可抢占: 锁不能被强制释放, <font style="color:blue">只有持有者主动释放后其它线程才能获取</font>**
4. 循环等待: **多个线程之间形成一种资源等待的闭环**, 比如线程 A 等待线程 B 持有的资源, 线程 B 又等待线程 C 的资源, 最终某个线程又反过来等待线程 A, 造成整个系统卡死

**<font style="color:blue">想要避免死锁, 就必须破坏其中至少一个条件</font>**. 常见的方式有:



- **资源的有序分配 (破坏"循环等待")**

**<font style="color:blue">做法就是保证线程申请锁的顺序要一致</font>**, 比如线程 A 和 B 获取的资源一样的话, 线程 A 是先尝试获取资源 A, 再尝试获取资源 B; 线程 B 同样也是先尝试获取资源 A, 然后尝试获取资源 B

优势是简单可行, 并且能彻底避免死锁 (**<font style="color:blue">因为只要所有线程按统一顺序加锁, 永远不会出现循环等待</font>**)

> **但这种方式有一定局限性, 它适用于锁资源数量和获取顺序可以控制**的系统, 在复杂场景中灵活性较差, 甚至难以实施. 比如一些线程为了遵循加锁顺序, **<font style="color:blue">可能要提前持有不需要的锁</font>**, 造成锁等待的时间变长; **此外有些线程是在运行过程中, <font style="color:blue">根据业务数据决定要锁哪个资源</font>**, 这就没法静态规定顺序



- **使用 "尝试锁(tryLock)" 机制 (破坏"不可抢占")**

> 它是 JUC 包下 Lock 接口中的方法, **最常用的实现类是 ReentrantLock**
>
> ```java
> // ReentrantReadWriteLock 中的 ReadLock 和 WriteLock 也都实现了 Lock 接口
> // 所以也支持 tryLock 方法
> ReentrantReadWriteLock lock = new ReentrantReadWriteLock();
> ReentrantReadWriteLock.ReadLock readLock = lock.readLock();
> ReentrantReadWriteLock.WriteLock writeLock = lock.writeLock();
> ```
>
> 另外 StampedLock (一个 Java8 引入的高性能锁类) 虽然不是 Lock 接口的实现类, 但其中也提供了类似 tryLock 的机制

ReentrantLock 中的 tryLock 方法有两个重载版本:

- `boolean tryLock()`: 没有方法参数的非阻塞版本 (也就是立即返回). 尝试获取锁时, **<font style="color:blue">如果锁未被占用, 立即返回 true; 否则立即返回 false, 不会阻塞</font>**
- `boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException`: 限时阻塞版本. 在指定时间内尝试获取锁, **若在这段时间内成功获取到锁就返回 true, 否则超时返回 false**



- **其次还可以<font style="color:blue">使用多线程调试工具检测潜在死锁</font>, 比如:**

使用 JDK 自带命令: jstack 可打印线程的堆栈信息; 或者使用像 JConsole / VisualVM 这样的监控工具

> **<font style="color:blue">另外 Java 中的 `java.lang.management` 包提供了检测死锁的工具</font>**
>
> **使用 ThreadMXBean 类中的 `findDeadlockedThreads()` 方法可以监控运行时死锁**
>
> ```java
> ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();
> long[] deadlockedThreads = threadMXBean.findDeadlockedThreads();
> 
> if (deadlockedThreads != null) {
> 	System.out.println("Deadlock detected!");
> 	// 可以进一步获取 ThreadInfo 来分析
> }
> ```



- 最后还可以通过**减少锁的持有时间、使用更高层次的并发工具、避免嵌套锁**等方式来避免死锁

首先尽量缩短锁的持有时间, 确保在锁内执行的操作尽可能少, 这样就可以减少发生死锁的机会

**另外 Java 提供了许多高级并发工具类**, 如 JUC 包下的 `ConcurrentHashMap` / `Semaphore` / `CountDownLatch`等, 这些工具类在设计时就考虑了并发访问的安全性并减少了死锁的可能性

**避免嵌套锁其实就是<font style="color:blue">尽量避免一个线程在持有一个锁的同时去获取另一个锁, 因为这会增加发生死锁的风险</font>**

> 最后补充一下死锁的典型特征:
>
> 1. 线程状态长期处于等待状态 (BLOCKED 或 WAITING)
> 2. CPU占用率突然下降 (等待状态不占CPU资源)
> 3. 日志输出停滞在关键资源获取前
> 4. 通过工具检测到"deadlock"关键字

# synchronized & Lock

## synchronized和Lock的区别

这个问题我觉得可以从几个方面来谈, 首先是**本质区别**

**synchronized 是 Java 的一个关键字**, 是语法层面提供的内置锁, 使用起来比较简单, 也不容易出错

**而 Lock 是 JUC 包中的一个接口**, 像 ReentrantLock 就是它的实现类, **<font style="color:blue">它是 JDK 5 引入的一种更灵活的锁机制</font>, 程序员要自己负责加锁和释放锁**, 出错的可能性也更大一点



从语法形式上来说, **<font style="color:blue">synchronized 可以直接作用在方法声明上, 也可以加在代码块中</font>**; **而 Lock 只能通过代码块来实现锁的控制**, 不能直接修饰整个方法



另外在控制方式上也有差异, **synchronized 是靠 JVM 和编译器自动完成加锁和释放的**, 程序员不需要管

而 **Lock 需要程序员手动调用 lock() 和 unlock() 方法来加锁和解锁,** 所以在使用的时候必须小心, **<font style="color:blue">比如要用 try-finally 语句块确保锁一定会被释放</font>**



一般来说普通的并发需求, 比如多线程互斥访问共享变量, synchronized 其实就够用了

但当遇到更复杂的需求, 比如:

- 想要一个公平锁 (也就是谁先等锁, 谁就先拿到锁)、需要支持读写分离的锁、需要自定义更灵活的等待 / 唤醒机制; 或者希望**<font style="color:blue">等待获取锁的时候能响应中断</font>**以及**需要支持加锁时设置超时时间**

这些情况 synchronized  就搞不定了, 这时候就需要用 Lock 接口的实现类来完成. **此外在涉及多个条件队列中的定向唤醒时**, Lock 配合上 Condition 接口就可以很好地解决

> 举个例子, 假设现在要写一个缓存组件, 这个组件需要允许多个线程同时读取, 但写操作必须是排他的. 而用 synchronized 是做不到 "读读并发、读写互斥" 的
>
> 这种读写分离的需求就得用 `ReentrantReadWriteLock`, 这个类中提供了读锁和写锁, 其中读锁可以并发, 写锁是互斥的



最后**<font style="color:blue">两者的底层实现也是完全不同的</font>**

- **synchronized 是 JVM 层面实现的, <font style="color:blue">它的底层是通过一个叫 Monitor(监视器)的结构来完成的</font>**

  - 在使用 synchronized 时对象在 JVM 中会有一个关联的 Monitor, **当线程进入 synchronized 修饰的代码块或方法时, 实际上就是尝试去获取这个对象的 Monitor**

  - **<font style="color:blue">而加锁的状态信息是记录在对象头里一个叫 Mark Word 的结构中</font>**


- **而像 ReentrantLock 这种 Lock 的实现类, <font style="color:blue">底层是基于 AQS 来实现的</font>**, 这套机制是 Java 并发包的核心, 用来管理线程的排队、等待、唤醒等逻辑, 非常强大但也更复杂一些

## 悲观锁和乐观锁的区别

**悲观锁就是指<font style="color:blue">在每次访问共享资源时, 都认为还有别的线程会来一起操作</font>, 所以每次操作共享资源时都会上锁, 从而保证只有一个线程能访问该资源.** 这样其它线程想拿到这个资源就会一直阻塞直到锁被持有者释放

+ 像 Java 中的 synchronized 和 ReentrantLock 就是悲观锁思想的实现. 它们同时也是独占锁, 也就是同一时刻只能有一个线程访问临界区, 其他线程都要等待 (事实上**<font style="color:blue">悲观锁往往就是通过独占锁机制来实现的</font>**)
+ **悲观锁的特点就是操作前先上锁, <font style="color:blue">线程之间是串行化访问, 互相阻塞</font>**
+ 优点就是简单安全, 但是性能比较低, 容易发生锁竞争, **如果操作不当还容易导致死锁**



**而乐观锁就<font style="color:blue">总是假设最好的情况, 认为共享资源每次被访问的时候不会出现问题, 所以不加锁直接操作</font>. 最后在提交修改的时候再去验证有没有发生并发冲突, 冲突了就重试**

+ Java 中的**原子类(比如 AtomicInteger)就是乐观锁的一种典型实现**, 底层依赖于 CAS 实现无锁的并发控制
+ 乐观锁的特点就是非阻塞的并发控制, 高性能, **<font style="color:blue">适用于读多写少的场景</font>**
+ 其**优点就是吞吐量高, 缺点是会出现 "ABA" 问题**(也就是值虽然没变但状态变过); 另外在并发量比较高的情况下如果反复尝试更新某个变量, 却又一直更新不成功, 会导致重试过多浪费 CPU

### 介绍一下它们各自的使用场景

悲观锁比较适用于**<font style="color:blue">写操作较多、并发冲突频繁的情况 (比如库存扣减)</font>**. 因为**悲观锁在操作前会先上锁, 开销是固定的**, 避免了频繁加锁失败和重试导致的性能问题

- 此外**<font style="color:blue">悲观锁也适用于同时操作多个共享变量的场景</font>**, 比如银行账户转账的业务, 就涉及了多个共享资源并且需要保证操作的原子性



而**乐观锁通常多用于读多写少的场景, 因为这样可以避免频繁加锁影响性能**

- 不过**<font style="color:blue">乐观锁主要针对的对象是单个共享变量</font>**. 因为如果要操作多个变量, 需要保证多个 CAS 操作一起成功, 但**因为没有多变量的 CAS, 所以只能逐个 CAS**
  - 此时问题就来了, 假如第一个变量更新成功, 第二个变量更新失败, **<font style="color:blue">系统就处于 "部分更新" 的中间状态</font>, 不符合原子性, 所以又需要把第一个变量回滚回去**, 否则数据不一致
  - 此外**多个变量下解决 ABA 问题也比单变量的情况更麻烦**
- 乐观锁的实际使用场景有: 比如记录点赞数 / 浏览量的统计, 每次写入都比较轻量, 针对的也是单个共享变量, 使用 Java 提供的原子类就能实现

## ABA问题是什么, 如何避免

ABA 问题指的是在进行 CAS 更新的过程中, 假如读取到的值是 A, 然后准备赋值的时候仍然是 A, 那么 CAS 就不会认为有问题发生, **<font style="color:blue">因为 CAS 在比较时只会检查当前值是否等于预期值</font>**

但是**<font style="color:blue">实际上有可能 A 的值在之前被改成了 B</font>, 然后又被改回了 A**, 然而 **CAS 在这种状况下无法判断这个值是否曾经被改过**, 这个更新的漏洞就叫做 ABA 问题



Java 中有两种常用方案解决 ABA 问题

+ 第一种是使用 `AtomicStampedReference`自带的**版本号机制, 在 CAS 操作中引入一个标记一起参与比较**
  + 这个标记就类似于版本号, **<font style="color:blue">每次修改不仅变更值, 还要变更版本号</font>**
  + 如果中途标记被别人改了, 即使值没变, CAS 操作也会失败
+ 另外也可以使用 `AtomicMarkableReference`, 它类似于 `AtomicStampedReference`, **<font style="color:blue">但它只用一个布尔值作为标记, 而不是 int</font>** -- **比较适用于那些不关心版本号只关心数据是否被修改过的场景**
+ 实际上**抛开 Java, 解决 ABA 问题的核心思路**只有一个:
  + 也就是**<font style="color:blue">给变量附加额外的变化信息, 来检测是不是值虽然相同但其实经历过变化</font>**

# 线程池

## 讲一下线程池的参数

优质博客: https://blog.csdn.net/Yunwushenyanying/article/details/137886037

通过 ThreadPoolExecutor 自定义线程池时有**七个核心参数**:

1. **corePoolSize (核心线程数)**

   - 表示保持常驻的线程数量, 即使它们处于空闲状态也不会被回收, **除非 `allowCoreThreadTimeOut` 被设置为 true, <font style="color:blue">如果该参数为 true 当核心线程空闲时间超过 keepAliveTime 的话就会被销毁</font>**, 比较适用于一些需要使用临时线程池的轻量任务, 可以节省资源

2. **maximumPoolSize (最大线程数)**

   - 表示线程池中允许同时存在的最大线程数量, **当任务量大时可以临时创建超过核心线程数的线程**

3. **keepAliveTime (存活时间)**

   - 表示**<font style="color:blue">非核心线程空闲后的最大存活时间</font>**, 超过这个时间就会被销毁

4. **unit (时间单位)**

   - 就是**<font style="color:blue">配合 keepAliveTime 参数使用的时间单位</font>**
   - 比如有 `TimeUnit.SECONDS` (秒)、`TimeUnit.MILLISECONDS` (毫秒) 等

5. **workQueue (任务队列)**

   - 用来缓存等待执行的任务,  **新任务来的时候会先判断当前运行的线程数量<font style="color:blue">是否达到核心线程数, 如果达到的话新任务就会被存放在队列中</font>**

6. **threadFactory (线程工厂)**

   - 生成新线程的工厂, **可以自定义来设置线程名称和优先级等信息**, 便于调试和监控

7. **handler (拒绝策略)**

   - 其实就是**<font style="color:blue">当线程数达到最大线程数量且队列也满了之后处理新任务的方式</font>**

   > 当一个新任务交给线程池, 如果此时线程池中**有空闲的核心线程就会直接执行; 如果核心线程满了就会将该任务加入到阻塞队列中**
   >
   > 如果阻塞队列也满了就会创建一个新线程 (也叫做救急线程) 来执行新提交的任务
   >
   > 但如果当前线程池中的线程数已经等于了最大线程数并且队列也满了的时候, 就不会再创建新线程, 而会去执行拒绝策略

## 都有哪些拒绝策略

Java 提供了四种内置的拒绝策略, 分别是:

- **AbortPolicy: <font style="color:blue">默认策略</font>, 直接抛出 `RejectedExecutionException` 异常**, 让调用方知道任务被拒绝
- CallerRunsPolicy: 让**使用线程池的调用者所在线程**自己去执行被拒绝的任务
- **DiscardPolicy**: 不做任何处理, **<font style="color:blue">直接放弃本次任务</font>**
- DiscardOldestPolicy: 丢弃队列中最老的任务, 然后提交新任务



此外, **还可以通过实现 `RejectedExecutionHandler` 接口来自定义拒绝策略**

## 什么情况会用无界队列, 什么情况用有界队列

先说什么时候用无界队列

+ 首先如果**<font style="color:blue">系统内存充足</font>, 可以容忍大量任务积压在队列中**, 使用无界队列可以避免任务被拒绝
+ 其次如果任务的处理时间较短, 且任务提交速率不会持续高于任务处理速率, 使用无界队列可以简化系统设计

使用无界队列的优点就是可以无限接收任务, 不会因为队列满而拒绝任务; 另外也可以平滑任务提交速率的波动, 避免因为短暂的高峰导致任务被拒绝

而缺点就是**<font style="color:blue">使用无界队列时如果提交任务的速度大大快于处理速度, 队列长度无限增长, 可能导致 OOM (也就是内存溢出)风险</font>**. 另外如果大量任务积压在队列中, 新任务的响应时间可能会变长



然后再说什么时候用有界队列

- 首先如果**任务量比较大, 或者需要限制线程池同时处理的任务数量时**就应该使用有界队列. 因为有界队列可以防止系统因为过度负载而崩溃, 还可以**<font style="color:blue">避免过度消耗资源 (比如数据库连接)</font>**
- 此外当**<font style="color:blue">任务的处理速度低于任务到达速度时</font>**, 使用有界队列可以**帮助控制积压的任务数量**, 防止系统过载

有界队列的优点就是可以控制队列的最大长度, **<font style="color:blue">避免因为任务积压过多导致的内存溢出</font>**; 另外当队列满时任务提交会被拒绝, **可以及时发现和处理问题**

缺点就是当队列满时, 新提交的任务会被拒绝, 需要处理任务拒绝策略. 增加了系统的复杂性

## 线程池常用的阻塞队列有哪些



# ThreadLoacl

优质博客: https://blog.csdn.net/Beyondczn/article/details/107132337

## 介绍一下ThreadLocal的作用和常见使用场景

ThreadLocal 是 **JDK1.2 时引入的一个类, 位于 java.lang 包中**. 其作用就是**<font style="color:blue">为每个线程提供线程内部的局部变量, 不同的线程之间不会相互干扰</font>**

- 可以将其比喻为一个 "存放数据的盒子", 每个线程都有自己独立的盒子, 用于存储私有数据

它常用于简化在同一线程内多个方法或组件之间共享数据的场景, **<font style="color:blue">避免显式地通过参数进行传递</font>**. 该变量的生命周期与线程一致, 线程结束后会被回收

> 要注意的是**<font style="color:blue">一个 ThreadLocal 实例在每个线程中只存一个值</font>**, **但可以将这个值设计成一个容器类型, 比如 Map 或对象, 以此间接存多个值**



然后再说 ThreadLocal 的常见使用场景:

- **比如在处理一个 HTTP 请求时**, 可以**<font style="color:blue">将请求的相关数据存储到 ThreadLocal 中</font>**, 然后在服务层和数据访问层就可以直接从 ThreadLocal 中获取这些数据, 无需在每一层都显式地传递参数

  - 比较常见的场景就是**<font style="color:blue">用户上下文的传递</font>:  在处理登录用户的请求时, 通常需要在多个方法间共享当前用户信息**, 并且不想在每层方法都加参数传递用户对象, 此时 ThreadLocal 就能派上用场

  ```java
  // 在登录拦截器或过滤器中 UserContextHolder.set(user);
  // 后续有需要的话随时 UserContextHolder.get(); 拿到当前登录用户
  public class UserContextHolder {
      private static final ThreadLocal<User> userHolder = new ThreadLocal<>();
  
      public static void set(User user) {
          userHolder.set(user);
      }
  
      public static User get() {
          return userHolder.get();
      }
  
      public static void clear() {
          userHolder.remove();
      }
  }
  ```

- 另外 SpringSecurity 内部就使用了 ThreadLocal 存储当前认证用户的 SecurityContext (即安全上下文), 实现了**安全上下文信息的线程隔离共享**

## 说一下ThreadLocal的底层实现

ThreadLocal 的实现**<font style="color:blue">依赖于 Thread 类中一个叫 ThreadLocalMap 的字段</font>**. 也因为它是类中的成员变量, 所以**每个线程都有自己独立的 ThreadLocalMap, 天然具备了线程安全性**



ThreadLocalMap 的作用就是**<font style="color:blue">维护当前线程内所有 ThreadLocal 对象与其对应值的映射关系</font>**. 它没有实现 Map 接口, 但是用独立的方式实现了 Map 的功能, **其底层用一个 Entry 数组来存数据**

- 这个 **Entry 的 key 是一个 ThreadLocal 的弱引用, value 就是要保存的资源** (也就是该线程专属的局部变量副本). 这样的结构造就了每个线程都只能访问属于自己的那份数据副本, 彼此之前不会干扰

> 此外 ThreadLocalMap 中**<font style="color:blue">使用的是开放地址法解决哈希冲突</font>**: 开放地址法是一种解决哈希冲突的策略, 发生冲突时在数组中继续线性探测下一个可用槽位
>
> 也就是每次冲突后就向后挪一位, 直到找到空槽或者目标 Entry



当调用 ThreadLocal 的 **set 方法**时:

- **就是以<font style="color:blue">当前的 ThreadLocal 作为 key, 以资源为 value</font>, 然后放到 ThreadLocalMap 里面**



调用 **get 方法**的时候: 

- **就是以当前的 ThreadLocal 为key, 然后从 ThreadLocalMap 中取值**
- 找到了的话就直接返回; **<font style="color:blue">如果没找到则会调用 initialValue 方法获取一个初始值</font> (该方法默认返回的是 null, 但是可以通过方法重写来自定义)**, 然后将其放到 ThreadLocalMap 中并返回



调用 **remove 方法**的时候:

- 会先获取当前线程对象中维护的 ThreadLocalMap 对象, **如果此 Map 存在就会以当前 ThreadLocal 为 key 删除对应的 Entry**

## 为什么ThreadLocal有内存泄漏问题

其实如果正常的去 `new Thread()`, **<font style="color:blue">用完之后线程结束, Thread 对象正常销毁</font>, 那么 Thread 类中的 ThreadLocalMap 也就会被垃圾回收了**, 不会出现内存泄漏问题

> 这里要注意 ThreadLocal 对象本身不会立即被垃圾回收, 直到没有其它引用指向它为止



**但问题是实际开发中基本都是使用线程池**, SpringBoot 项目处理请求的时候也是从 tomcat 线程池中拿出来一个线程再去处理的. **<font style="color:blue">而线程池中的线程不会被销毁, 会一直复用</font>**

也就是说这种情况会一直存在一条引用链

​	**从 Thread -> ThreadLocalMap -> Entry -> key -> 再到 ThreadLocal**

即便不想用 ThreadLocal 了, **将这个 ThreadLocal 对象设置为 null, 这条引用链也是存在的, Entry 对 key 的引用也是存在的**. 也就是说即使这个 key 对应的 ThreadLocal 已经不用了, 也仍然没有办法被当作垃圾回收

所以要把这个 key 设置成弱引用, 因为**如果它被弱引用关联的话, <font style="color:blue">那么只要发生了垃圾回收, 它就能够被直接回收</font>, 从而避免 key 导致的内存泄漏问题**



而 value 不需要使用弱引用是因为我们将数据存到 value 中是为了后面去用它, **如果 value 是弱引用可能出现<font style="color:blue">资源被放入, 但是暂时没有拿出来导致没有强引用指向它, 然后因为是弱引用所以 GC 后资源就会被回收</font>的问题**

但是**也因为 value 是强引用**, 所以即使后期 value 不用了也仍然会一直存在一个从

​	**<font style="color:blue">Thread -> ThreadLocalMap -> Entry -> 再到 value 的引用链, 因此是无法被垃圾回收的</font>**

**从而会导致因为 value 的内存泄漏**. 所以在使用完 ThreadLocal 之后要调用 remove 方法删除对应的 Entry 防止内存泄漏问题



另外但其实当 **ThreadLocalMap 内部调用 set / get / remove 中的任意方法的时候<font style="color:blue">会对所有 key(也就是 ThreadLocal 对象)进行是否为 null 的判断</font>**

​	**如果 key 为 null, 则清除失效的 Entry -- 从而避免内存泄漏**

这就意味着使用完 ThreadLocal 之后, 即使当前线程依然运行的前提下, **就算忘记调用 remove 方法, 弱引用也比强引用可以多一层保障**



虽然 ThreadLocal 通过弱引用机制具备一定的自清理能力, 但**仍然应该在每次使用完之后调用 remove 方法**, 尤其在使用线程池时, 这是防止内存泄漏的唯一可靠手段





























































