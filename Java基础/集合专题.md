# 公共问题

## HashMap 和 Hashtable的区别

参考博客: https://blog.csdn.net/2301_81519676/article/details/141176193

- **产生时间不同**: Hashtable 产生于 JDK1.0, 而 HashMap 产生于 JDK1.2
- 虽然 Hashtable 和 HashMap 都实现了相同的三个接口 (Map, Cloneable, Serializable), 但两者继承的父类并不同
  - **<font style="color:blue">Hashtable 的父类是 Dictionary [一个已经被废弃的类]</font>**
  - **HashMap 的父类是 AbstractMap**
- **在 JDK1.8 及其之后, HashMap 底层结构是数组 + 链表 +红黑树(即哈希表 + 红黑树); 而 Hashtable 的底层结构是数组 + 链表(即哈希表)**, 整体架构和 JDK1.0 保持一致
- **初始化时机不同**: **<font style="color:blue">HashMap 在第一次添加元素时</font>**才开辟 table 数组空间 (延迟初始化); **Hashtable 在构造方法**中就会开辟 table 数组空间
- **初始容量不同**: 使用无参构造创建 HashMap 的**<font style="color:blue">初始容量为 16, 如果使用了有参构造初始容量会自动向上调整为最近的 2 的幂</font>**; 使用无参构造创建 Hashtable 的**初始容量为 11**, 有参构造初始容量可以是在 **int 范围内的任何正整数**

> 它们默认的加载因子都是 0.75, 也都支持通过构造函数**手动修改加载因子**. **根据泊松分布模型, 当加载因子为 0.75 时, <font style="color:blue">一方面可以减少哈希冲突, 另一方面也避免了不必要的内存浪费</font>**
>
> 加载因子(loadFactor)用于控制**哈希表的空间利用率与性能之间的权衡**, 当哈希表中元素的个数达到阈值**(`threshold = table 数组容量 × 加载因子`)**时, 就会触发扩容

- 扩容方式不同: 当元素个数达到阈值时, **<font style="color:blue">HashMap 会扩容为原数组长度的 2 倍; Hashtable 扩容为原数组长度的 2 倍 + 1</font>** (扩容时都会进行 rehash 并移动元素)
- **<font style="color:blue">Hashtable 的 key 和 value 都不能为 null</font>**. 因为 Hashtable 在**计算 hash 值时是直接调用了 `key.hashCode()` 方法**, 如果此时 key 为空会抛出空指针异常; 另外在 Hashtable 的 **put 方法中用 if 判断了 value 是否为 null**, 如果为 null 也会抛出空指针异常
  - HashMap 中的 key 和 value 都可以为 null, 因为 HashMap 的 hash 方法中对 `key == null` 做了单独判断, `key == null` 时会跳过 hash 计算, **直接将 key 放在 0 号桶(table[0])上**
- **HashMap 在多线程下线程不安全**; 而 Hashtable 的每个方法都加了 synchronized, 所以多线程下线程安全, 但性能较差
  - 但**现在更推荐使用 `ConcurrentHashMap` 替代 Hashtable **以兼顾安全与性能
- HashMap 中 hash 值的计算方式: `(key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16)`, **<font style="color:blue">这是对`key.hashCode()`的高 16 位和低 16 位做异或操作</font>**. 这种操作叫做**扰动函数, 扰动处理可以降低 hash 冲突, 使 hash 分布更均匀**
  - Hashtable 中 hash 值的计算方式: `key.hashcode()`, 无扰动处理, 容易产生哈希冲突
- Hashtable 插入元素采用的是头插法; HashMap 自 JDK1.8 开始改为了尾插法

## HashMap和HashSet的区别

首先 HashMap 实现了 Map 接口; HashSet 实现的是 Set 接口

**HashSet 仅存储元素, 不存储映射关系; HashMap 存储键值对, 每个 key 映射一个 value**



其次使用 HashMap 时需要调用 put 方法向 Map 中添加元素; 使用 HashSet 时要调用 add 方法向其中添加元素

在 HashMap 中使用 key 来计算 hashcode; 而 HashSet 使用成员对象来计算 hashcode 值 



**<font style="color:blue">最后由于各自的特点, 用途也有所不同</font>**: **HashSet 适合用于去重、判重这种只关注值本身的场景**(比如过滤重复元素 / 黑名单检查); **而HashMap 适合用于查表、映射的场景**

# List

## ArrayList的扩容机制

ArrayList 底层是基于数组实现的, 容量是动态扩展的. 它有两种初始化方式:

- **<font style="color:blue">使用无参构造时, 一开始底层数组其实是空的, 真正分配空间是在第一次添加元素的时候</font>**, 这时会初始化一个**长度为 10** 的数组
- 使用有参构造时, 底层会立即分配指定大小的数组, 不需要等到添加元素

每次添加元素之前, ArrayList 都会检查当前数组是否还有空间. **当当前元素个数(size)等于数组长度时, 说明数组已经满了, 此时就会触发扩容操作**

**<font style="color:blue">扩容的策略是把容量扩为原来的 1.5 倍, 也就是旧容量加上旧容量的一半</font>**. 扩容时会创建一个更大的新数组, 然后把原数组里的元素全部复制进去, 所以这是一个有开销的操作



为了减少扩容次数, 应该在知道大致数据量的情况下使用有参构造预先分配好容量. **另外 ArrayList 的最大容量限制是 `Integer.MAX_VALUE - 8`**, 用来避免内存溢出

> 之所以减 8, 是为了给数组对象本身的元数据 (比如对象头、对齐填充等) 预留空间

## ArrayList和LinkedList的区别

**首先它们内部的数据结构不同**

- **<font style="color:blue">ArrayList 基于动态数组实现</font>, 所以在内存中声明的是一段连续的空间**

- **LinkedList 基于双向链表实现** (JDK 1.6 之前是循环链表, JDK 1.7 取消了循环)



其次它们的**<font style="color:blue">随机访问的效率也不同</font>**

- **ArrayList 支持通过索引进行快速随机访问**，时间复杂度为 O(1)
- LinkedList 随机访问性能较差. 因为需要从头或尾开始遍历链表，时间复杂度为 O(n)



然后再说**插入和删除操作的效率**

- ArrayList 在尾部进行插入和删除操作是高效的, 但在中间或开头插入和删除需要移动元素, 性能较差
- LinkedList 在任意位置的插入和删除操作效率都比较高, 因为只需要调整节点之间的指针. **但是 LinkedList 是不支持随机访问的, 所以除了头结点外插入和删除的时间复杂度都是 O(n), 效率也不是很高**
  - **<font style="color:blue">也因此 LinkedList 基本没人用</font>** (就连 LinkedList 的作者自己都说从来不用 LinkedList)
  - 需要用到 LinkedList 的场景几乎都可以使用 ArrayList 来代替, 并且性能通常会更好

# Set

## HashSet是如何实现去重的

**因为 HashSet 底层依赖 HashMap 实现, <font style="color:blue">每次调用 add 方法实际是执行内部维护的 HashMap 的 put 方法</font>**. **其中插入的 key 就是 add 传入的参数**

而 value 是一个固定的 Object 对象, 由 `static final` 修饰, 所有元素共享

- **<font style="color:blue">所以 HashSet 的去重逻辑完全等价于 HashMap 的 key 不重复的机制</font>**
- 也就是依赖于元素的 `hashcode()` -- 用于定位哈希桶 (也就是数组下标) 以及 `equals()` -- 用于判断两个数据"逻辑上是否相等"



插入元素时, 先计算元素的 `hashCode()`, 确定存储位置

- 如果这个桶是空的说明之前没有任何元素, 直接插入
- **如果这个桶有元素, 就遍历桶中的每个节点并且同时用 `equals()` 方法做对比**, 有任何一个返回 true 就说明已有"逻辑重复"的元素 -- 不插入
  - 如果所有都返回 false, 说明是新元素 -- 插入



# Map

## HashMap中put一个数据的过程

首先在 put 方法内部会执行 `putVal` 方法, 在该方法内在执行真正的插入逻辑

第一步: 调用 hash 方法计算哈希值, 将key作为参数传入进去. **<font style="color:blue">在内部会调用 `key.hashcode()`, 然后用高 16 位异或低 16 位, 让高位也参与运算, 做扰动处理</font>**, 让哈希值的分布更加分散, 尽量避免哈希冲突

**在其中会对 `key == null` 做判断, 如果为 null 的话返回的 hash 值就是 0, 将来就会将数据放到 0 号桶的位置**



第二步: 初始化检查 -- 第一次调用 put 方法时, 会发现 table 为空. 然后调用 `resize()` 进行数组的初始化, 使用无参构造方法的话在这一步会**默认初始化一个长度为 16** 的 Node[] 数组

**如果使用的是有参构造方法, 会通过 `tableSizeFor` 方法<font style="color:blue">计算得到传入容量向上最接近2的幂次方的值</font>**, 然后初始化该长度的数组

**<font style="color:blue">但无论是哪种方式, table 都是延迟初始化的</font>** (也就是懒加载)



第三步: **<font style="color:blue">通过 `当前数组长度减一 按位与上 刚才经过扰动处理得到的hash值` 的方式</font>**定位数组下标 (也就是桶), 用位运算代替了取模, 可以更高效地计算索引



第四步: **判断当前该索引位置的桶是否为空, 如果为空就构造节点并插入**



第五步: 如果桶不为空, 说明发生了哈希冲突, 就会进入冲突处理逻辑. **<font style="color:blue">如果发现桶中第一个元素的 hash 值和 key 一样, 并且通过 equals 比较后也相等</font>** -- 就表示是同一个 key, **直接更新它的 value 值即可**

不是的话进入下面的判断逻辑



第六步: **<font style="color:blue">如果桶中第一个节点属于红黑树的节点类型, 就会调用 `putTreeVal` 方法</font>**. 该方法会从根节点开始一边比较 hash, 一边比较 key

如果找到了重复的 key, **就会返回这个已有节点, 然后在外层的 `putVal` 方法中做更新.** 如果没有找到重复的 key 就插入合适的位置



第七步: 如果不是红黑树结构而是链表结构, 那么就会遍历链表逐个比较 key. **如果找到了相同的 key 就返回, <font style="color:blue">跟之前一样会走外层 `putVal` 方法中的统一更新逻辑</font>**

如果遍历完链表都没找到, **就会在链表尾部添加一个新节点** (也就是所谓的尾插法)

**在这期间如果发现链表长度大于等于八, 就考虑把链表转换成红黑树. **但转换前还会判断数组的长度是否大于等于64, 不满足的话就会选择先扩容而不是树化

至此插入逻辑结束, 回到外层的 `putVal` 方法



第八步: **先判断是不是更新操作** (也就是刚才插入过程中是否找到了重复的 key), 如果是的话就会更新旧节点的 value, 不会增加 size. 然后将旧值直接返回



第九步: 如果不是更新操作, 就让 size 加一之后再判断是否需要扩容

当 size 加一后满足 `size > threshold` (阈值默认就是容量 * 0.75)时, 就会触发 `resize()` 扩容操作

> 在这之后还会执行一个叫**<font style="color:blue"> `afterNodeInsertion` 的扩展钩子方法. 该方法在 HashMap 中只是一个空实现</font>**, 没有实际作用. **目的主要是给子类(也就是 `LinkedHashMap`)提供插入后要做的附加操作的机会**
>
>
> 另外其实在刚才第八步判断是否是更新操作的if语句块中也有一个叫 `afterNodeAccess` 的钩子方法. 默认实现也是空的, 但在 `LinkedHashMap` 也进行了重写
>



第十步: **新增元素成功, 将 null 作为返回值返回**, 插入逻辑彻底结束

## HashMap的扩容机制

+ **<font style="color:blue">当 HashMap 中存储的键值对的数量(size)超过 `当前集合容量(capacity) × 负载因子(loadFactor)` 时</font>**, 就会触发 resize 扩容操作
+ 默认情况下: capacity = 16; loadFactor = 0.75; 所以初始扩容阈值是: 16 × 0.75 = **12**
  + 也就是说当 HashMap 里放入第13个元素时, 就会触发扩容
+ 扩容的过程: 扩容时会将当前数组容量**翻倍**, 比如16→32 / 32→64, 并且需要**重新计算每个元素的哈希位置(rehash)**, 之后把元素挪到新数组的桶中
  + 注: Java8 中的 rehash 其实进行了优化: **通过位运算快速判断新位置是否是原索引或原索引 + 扩容长度(不再重新计算哈希值, 效率更高)**
+ **<font style="color:blue">另外如果某个桶中的链表长度达到 8, 但数组容量小于 64 时, 也会触发扩容</font>**

### 讲一下rehash

rehash 其实**就是 HashMap 扩容方法中的核心逻辑**, 作用就是在创建新数组后在将旧数组的元素移动过去时, 重新计算元素的下标位置



**在 JDK8 之前** rehash 的逻辑是**<font style="color:blue">对元素的 hash 值重新进行一次取模运算</font>**, **也就是 `e.hash & (newCapacity - 1)`**. 它会遍历旧数组的每个桶, 然后**把链表上的节点逐个头插到新数组的相应位置**

而在 JDK8 中进行了一个小优化, **<font style="color:blue">计算方式变成了判断 `e.hash & oldCap == 0`</font>** -- 这利用了基于 2 倍扩容的位运算特性, **扩容后只有一个比特位变化 (也就是新的最高位)**

- **如果结果为 0**, 就说明 hash 值在多出来的这一位上是 0, **那么新下标和旧下标一致**
- **如果结果不等于 0**, 就说明 hash 值在这一位上是 1, **<font style="color:blue">那么新下标就等于旧下标加上旧数组容量</font>**



另外从 JDK8 开始, 链表中数据的迁移方式从之前的头插法变成了:

**在遍历旧链表时, <font style="color:blue">同时维护两条链表,  lo 链表和 hi 链表</font>**. lo 链表存储留在原索引位置的元素, hi 链表存储要移动到新位置的元素

遍历结束后, **把 lo 链表挂到新数组的原索引位置, hi 链表挂到新数组中偏移数组旧容量的索引位置**. 这样做既保持了原链表的顺序, 性能也更好

## 介绍一下HashMap的存储结构

+ HashMap 从 JDK1.8 开始的底层结构是: 数组 + 链表 + 红黑树(三者结合)
  + **<font style="color:blue">它根据 key 的 hash 值定位到数组中某个位置, 再通过链表 / 红黑树存储冲突元素</font>**
+ HashMap 存数据的过程: 先计算哈希值然后定位数组索引, 之后检查该位置
  + 位置为空就直接放进去
  + 已有节点(哈希冲突): **遍历链表, 如果 key 相同 → 替换 value; 如果 key 都不同 → 插入链表尾部**, 如果链表长度超过阈值(**<font style="color:blue">默认 8, 等于 8 也满足条件</font>**) → 尝试转换为红黑树
  + 但如果只是链表长度 >= 8而数组长度小于64的话, **`HashMap`会选择先扩容而不是树化**. 
    + 因为如果数组太小, 冲突多可能只是**桶太少**导致的
    + 等数组变大后如果仍然冲突才认为是哈希分布本身不均匀, 这时才转红黑树
  + **<font style="color:blue">因此只有当链表长度 ≥ 8 且数组容量 ≥ 64 时, 链表会转成红黑树</font>**
  + **红⿊树的树化阈值可以通过反射修改 TREEIFY_THRESHOLD(static final) 进⾏调整**

> 引入红黑树原因: 当哈希冲突太多, 链表过长, 查询效率变为O(n). 红黑树查找是O(log n), 效率更高

### 为什么不直接用红黑树

+ **<font style="color:blue">链表结构更简单, 占用内存更少</font>**(链表节点只需要一个 next 指针). 红黑树节点需要: left、right、parent、color, 至少 4 个引用
  + 如果大部分桶里根本没有冲突或者冲突节点很少, 直接用红黑树反而**更占内存且增加了维护的复杂度**
+ 其次红黑树维护成本也比较高: 红黑树虽然查询是 O(log n), 但插入和删除都涉及**树的旋转 和 颜色变换**, 算法复杂度高, CPU 成本也就高
  + **相比之下链表插入就是简单的 next 赋值, <font style="color:blue">对于节点数较少时链表更轻量</font>**

此外 HashMap 设计本意就是通过 **良好的 hash 函数**, 把 key 尽可能分散在不同的桶中, 让每个桶的冲突数量尽量少. 大部分桶一般只包含几个节点, 直接用链表就很高效, 没必要一开始就套个红黑树这么"重型的结构"

## HashMap从1.7到1.8为什么从头插改成尾插

参考博客: https://juejin.cn/post/7236009910147825719?searchId=202307221616567C1AAB8045817A64ED43

**<font style="color:blue">主要就是为了解决多线程环境下可能出现的链表成环问题</font>, 一旦形成环, HashMap 的扩容操作就会无限循环**. 因为遍历链表时永远找不到结尾, 进而导致 CPU 占满

这个问题在高并发场景下非常严重, 可能导致程序崩溃



举个例子, 比如现在有一个 HashMap, 其中有一个桶中有链表 `A -> B -> C`, 然后有两个线程 T1 和 T2 要对 HashMap 进行扩容

**假设线程 T1 先抢到了 CPU, 但当执行完 `next = e.next` 时时间片用完**, 这时对于 T1 来说, e 是 A, next 是 B

然后轮到线程T2开始执行扩容操作, 它一直执行到了扩容完成之后, T1 才被唤醒. **而由于是头插法, 所以 HashMap 的顺序已经发生了改变**, 假设这三个节点扩容后还是在原索引, 那么结构就变成了 `C -> B -> A`, 但**<font style="color:blue">线程 T1 对于发生的一切是不可知的, 它指向的元素也依然没变</font>**

而当线程 T1 恢复执行时, 死循环就建立了. 因为 T2 执行完扩容之后 B 节点的下一个节点是 A, 而刚才说过 T1 线程指向的首节点是 A, 第二个节点是 B, 这个顺序刚好和 T2 扩完容后的节点顺序是相反的

**也就是 T2 执行完后的顺序是 B 到 A, 而 T1 的顺序是 A 到 B**. 所以当 T1 线程将节点迁移到它自己的 newTable 的过程中就会发现, A 节点和 B 节点已经形成死循环了



而 Java 8 改用尾插法后: 

- **扩容时链表的相对顺序保持不变, 节点按原顺序插入新桶**
- 即使在多线程环境下, 链表也不会形成环, 极大提高了 HashMap 的健壮性

## HashMap为什么线程不安全, 在多线程环境下有什么问题

**<font style="color:blue">HashMap 的 put、resize 等操作都没有加锁</font>, 多个线程同时操作时会破坏内部结构**, 导致数据丢失或者链表成环的问题. **其中的链表成环问题从 JDK1.8 开始因为优化了数组扩容的方案, 已经可以基本避免了**

- 而 1.8 之前在多线程环境下进行 resize 扩容时就可能导致链表成环



**其次数据丢失问题在哪个版本中都存在**. **<font style="color:blue">比如多线程环境同时进行 put 操作, 并且写入的是同一个桶</font>**, 因为没有加锁, 就可能导致元素互相覆盖从而出现数据丢失的问题



**最后在多线程环境下如果一个线程调用了 get 方法读取数据, 而另一个线程在同时修改了结构** (比如增加或删除元素), 就可能导致**<font style="color:blue">读取操作得到错误的结果或者抛出并发修改异常</font>**

### 如何保证HashMap的线程安全

**<font style="color:blue">首先可以通过 `Collections.synchronizedMap()` 方法</font>**创建一个线程安全的 HashMap, **该方法会返回一个同步的 Map 包装器**, 使得所有对 Map 的操作都是同步的

```java
Map<String, String> synchronizedMap = Collections.synchronizedMap(new HashMap<>());
```

但要注意虽然用该方法返回的 Map 是同步的, 但当比如用 foreach 遍历时也要加锁, 因为遍历实际上是一个 "多步骤" 的过程

```java
// 这部分代码
for (Map.Entry<String, String> entry : map.entrySet()) {
    System.out.println(entry.getKey());
}

// 实际上执行的是下面这些步骤
Iterator<Map.Entry<String, String>> it = map.entrySet().iterator(); // 第一步: 创建迭代器
while (it.hasNext()) { // 第二步: 判断是否还有元素
    Map.Entry<String, String> entry = it.next();  // 第三步: 读取下一个元素
    // ...
}

// 在遍历过程中, 也就是 hasNext() 和 next() 之间如果有其它线程中途修改 Map, 遍历过程就不安全了
// 就会抛出并发修改异常 (ConcurrentModificationException)
```



另外也可以使用 HashTable 和 ConcurrentHashMap, **但是 HashTable 中同步的方式会让性能不达标**

**<font style="color:blue">而 ConcurrentHashMap 是专门设计用于多线程环境的哈希表实现</font>**, 更适合高并发场景使用



最后也可以在自定义的 HashMap 操作中使用**显示的锁 (比如 ReentrantLock)** 来保证线程安全

## HashMap中一次get()的时间复杂度是多少

在理想状态下, 也就是**没有发生 hash 碰撞的情况**. 访问的桶中只有一个元素时, **get 方法的时间复杂度是 O(1)**

如果发生了 hash 碰撞, 就可能需要进行遍历查找. **桶中有 n 个元素的情况下**, 如果桶中是链表结构的话查询的时间复杂度就是 O(n), 如果是红黑树结构的话就是 O(logn)





















