# 缓存穿透是什么, 怎么解决

**<font style="color:blue">缓存穿透是指当查询的数据在缓存和数据库中都不存在</font>, 导致每次请求访问缓存时, 都会发现缓存缺失, 直接将请求打到数据库**. 但因为数据库中也没有要访问的数据, 所以没办法构建缓存数据来服务后续的请求. 

那么当有大量这样的请求到来时, 数据库压力会骤增, 高并发环境下可能会压垮数据库. 此类请求往往是由攻击者恶意伪造无效请求参数引发的



应对缓存穿透的常见方案有三种:

- **第一种方案是限制非法请求**. 就是在接口的入口处判断请求参数是否合理, 比如根据实际情况判断是否是正整数、是否符合某种格式、是否落在合理的范围内等
  - **如果参数不符合基本规则, 也就确定是恶意请求, 直接拒绝**, 避免其进一步命中缓存或数据库, 从源头阻断穿透行为
  - 另外也可以对短时间内发送大量非法请求的 IP 进行限流或者拉黑处理
- **<font style="color:blue">第二种方案是缓存空值或者默认值</font>**. 也就是当发现缓存穿透现象时 (**即在数据库中查询结果为`null`**), 可以针对查询的数据, 在缓存中设置一个空值或者默认值, **<font style="color:blue">这样后续的请求就可以从缓存中读取到空值或者默认值, 然后直接返回给应用</font>**, 而不会继续查询数据库
  - 这种方式实现起来比较简单, 成本低. **但是空值缓存过多也会占用缓存空间**, 所以需要配合设置合理的 TTL
- **第三种方案是在缓存前加一层布隆过滤器, 用来快速判断数据是否存在**, 以此避免通过查询数据库来判断数据是否存在
  - 使用这种方式之前要将所有存在的 key 提前预热写入布隆过滤器中. 然后后续在新增数据时, 会在将数据写入数据库中后, 也将对应的 key 存入布隆过滤器中, 以确保其内容和数据库保持一致, 避免因为漏写导致拦截了合法请求
  - **在实际请求流程中, 业务线程先通过布隆过滤器判断请求的 key 是否可能存在于数据库中. <font style="color:blue">布隆过滤器会给出"可能存在"和"一定不存在"两种结果</font>**
    - 如果数据一定不存在, 就可以直接返回空值, 无需再访问缓存和数据库
    - 如果数据可能存在, 就继续执行缓存查询逻辑
  - 只有在缓存也未命中的情况下, 才会进一步访问数据库, 并在获取结果后回写到缓存中

## 布隆过滤器的实现原理

参考博客: https://blog.csdn.net/qq_63713674/article/details/143652034

**<font style="color:blue">布隆过滤器是由一个 "初始值都为0的位图数组" 和 "N个哈希函数" 两部分组成的</font>**. 当我们在向数据库写入数据时, 会在布隆过滤器中也做个标记, 这样在下次想知道数据是否存在时, 就只需要查询布隆过滤器. 如果查询到数据没有被标记, 就说明不在数据库中



布隆过滤器会通过3个操作完成标记:

- 第一步是使用 N 个哈希函数分别对数据做哈希运算, 得到 N 个哈希值
- 第二步, 将第一步中得到的 N 个哈希值对位图数组的长度取模, 得到每个哈希值在位图数组的对应位置
- 第三步, **将每个哈希值在位图数组的对应位置的值设置为1**



举个例子, 假设有一个长度为 8 的位图数组和 3 个哈希函数组成的布隆过滤器

在数据库写入数据 x 后, 把数据 x 标记在布隆过滤器时, 数据 x 会被 3 个哈希函数分别计算出 3 个哈希值, 然后再将这 3 个哈希值对 8 进行取模, 假设取模的结果为1、4、6, 然后就会把位图数组的1、4、6号索引位置的值设置为1

当应用后续需要判断数据 x 是否存在于数据库中时, 只需通过布隆过滤器检查位图数组的1、4、6这三个位置的值是否全部为1. 如果其中任意一个位置为 0, 就可以确定数据 x 一定不在数据库中



**布隆过滤器由于是基于哈希函数实现查找的, 所以高效查找的同时存在哈希冲突的可能性**. 比如数据 x 和数据 y 可能都落在1、4、6号位置, 而事实上可能数据库中并不存在数据 y, 存在误判的情况

**<font style="color:blue">所以, 当布隆过滤器查询到数据存在时, 并不一定证明数据库中存在这个数据</font>; 但是查询到数据不存在时, 数据库中一定就不存在这个数据**



**<font style="color:blue">此外布隆过滤器还有一个缺点, 就是不支持删除元素</font>**. **因为它的位图可能被多个元素同时命中, 删除一个元素会影响到其它元素的判断**, 导致误判"数据不存在"

**如果确实有删除需求, 可以通过计数型布隆过滤器** (也就是将位图数组变成整数数组, 每个位是一个计数器, 插入时对应位置加 1, 删除时减 1, 判断时只要值大于 0 就认为可能存在)或者定期重建布隆过滤器等方式来实现

> 此外在提供些其它的参考方式, 比如:
>
> 元素删除后虽然不能从布隆过滤器中删除掉, 但可以再加一层缓存, 比如把删除的数据加入到另一个集合(比如Set)中, 作为"删除标记集合". 查询时流程是:
>
> 1. 先查布隆过滤器 → 如果说"可能存在"
> 2. 再查 Set → 如果在 Set 中, 说明是被删除的元素 → 判为不存在
>
> 这样不需要修改原有的结构, **还可以满足删除元素后的复用问题, 动态维护删除状态**. 但缺点就是多了一次网络访问 (要查布隆 → 再查 Set); 此外发生删除操作的话要维护多个数据
>
> 
>
> 另外还可以使用"布谷鸟过滤器", 这里就不详细介绍了

# 缓存击穿是什么, 怎么解决

在平时的业务中通常会有一些数据会被频繁地访问, 这种数据一般被称之为热点数据

**<font style="color:blue">缓存击穿其实就是指缓存中的某个热点数据过期了</font>, 并且在其缓存失效期间恰好有大量的并发请求同时访问这个热点数据**. 然而因为无法从缓存中读取, 所以会直接访问数据库, 此时数据库很容易就被高并发的请求冲垮



想要解决缓存击穿问题, 首先可以选择在缓存重建时加互斥锁, 防止多个线程同时去查数据库. 未能获取到锁的请求, 要么等待锁释放后重新读取缓存, 要么就返回空值或者默认值

- 实现方式主要有两种, **一种是加 synchronized 或者 ReentrantLock 这种本地锁**, 但这种方式一般只适用于单机部署的场景, 因为本地锁的可见范围仅限于当前的 JVM
  - **<font style="color:blue">当部署多个节点时, 不同节点的 JVM 之间无法共享本地锁</font>**, 可能会导致多个节点同时认为自己拿到了锁, 从而失去了互斥效果
- 为了解决这个问题, **在集群环境下应该使用分布式锁. 比如基于 Redis 的 setnx 命令, 或使用 Redisson 提供的高级封装**. 通过 Redis 实现的分布式锁可以被多个服务实例共享, 从而真正实现跨节点的互斥控制



**另外一种比较常见的解决方案就是给热点数据设置成永不过期,** 也就是在 Redis 中不设置物理TTL, 保证缓存始终存在. **<font style="color:blue">然后在缓存数据时额外存储一个"逻辑过期时间"字段</font>, 由业务代码在读取缓存时判断数据是否已经逻辑过期** -- 如果没有逻辑过期, 就直接返回缓存数据; **<font style="color:blue">如果逻辑过期了, 先立即返回旧值, 然后与此同时异步触发一个缓存刷新操作</font>, 由后台线程更新缓存**

# 缓存雪崩是什么, 怎么解决

**<font style="color:blue">缓存雪崩就是指缓存数据在同一时间大面积的失效</font>, 导致大量的请求同时访问数据库**, 造成数据库压力骤增甚至宕机的现象

**此外 Redis 故障宕机也会导致缓存雪崩现象**, 导致所有的请求都会打到数据库上



**针对大量缓存同时失效的情况:**

- 首先可以设置随机的缓存过期时间. **<font style="color:blue">比如在固定过期时间的基础上加上一个随机值</font>, 这样就保证了数据不会在同一时间过期**

- 除此之外也可以不设置缓存的有效期, 而是**让缓存永久有效, 然后将更新缓存的工作交由后台线程定时更新**. 虽然一般不推荐这么设置, 但对于某些关键性和变化不频繁的数据, 可以考虑这种策略

- **<font style="color:blue">最后也可以针对热点数据提前预热, 将其存入缓存中并设置合理的过期时间</font>, 而不是等待用户首次请求才触发缓存构建**. 比如秒杀场景下的数据在秒杀结束之前不过期

  

**针对 Redis 服务不可用的情况:** 

- **<font style="color:blue">首先可以通过主从节点的方式构建 Redis 集群</font>**, 这样即使主节点故障宕机, 从节点也可以切换成为主节点, 继续提供缓存服务, 避免了由于 Redis 故障宕机导致的缓存雪崩问题
- **<font style="color:blue">另外也可以设置多级缓存, 例如本地缓存 + Redis 缓存的二级缓存组合</font>**. 当 Redis 缓存出现问题时, 还可以从本地缓存中获取到部分数据

- 其次也可以启动服务熔断或者请求限流机制. **比如 Redis 宕机时主动开启熔断逻辑, 避免雪崩蔓延到下游数据库系统**; 或者如果启用了请求限流的话, 就是只将少部分请求发送到数据库进行处理, 再多的请求就在入口直接拒绝服务, 等到 Redis 恢复正常并把缓存预热完后, 再解除请求限流的机制

# Redis中常见的数据类型及其使用场景

Redis中常见的基础数据类型有五种

- String: 也就是字符串, 但其实也可以存储整数或者浮点数, Redis 内部**会在特定命令下将存储的值作为整数或者浮点数处理 (比如 incr / incrby / incrbyfloat)**
  - **<font style="color:blue">但是如果用操作数值的命令操作非数值字符串会报错</font>**
  - String 一般常用于缓存对象、计数器、分布式锁以及存储 token 或者手机验证码等等



- List: Redis 中的 list 是一个双端链表结构, **支持从两端"推入 / 弹出"数据**, 另外还支持根据值删除元素
  - list 可以用作消息队列使用 (比如用 `lpush` + `brpop `搭配实现). **但是这样做有两个比较大的弊端: 1. 生产者需要自己为消息生成唯一ID; 2. 不能以消费组的形式消费数据**, 因为在 list 中数据被取出就意味着被删除了, 所以数据一旦被某个消费者取出, 其它消费者就拿不到了

> list 根据值删除元素语法: `LREM key count value` -- **<font style="color:blue">count = 0 的话就表示删除所有匹配的值</font>**, 小于零就表示从右往左删除最多 |count| 个, 大于零就是从左往右删除最多 count 个



- Hash: 比较类似于 Java 中的 Map, 是一种存储键值对的集合
  - 一般用于缓存对象 或者 **<font style="color:blue">存储需要频繁更新局部字段的数据</font>** (比如购物车)



- Set: 存储字符串的无序集合, 并且集合中的元素不允许重复. **此外 Redis 中的 set 结构还内置了<font style="color:blue">交集( sinter )、并集( sunion )、差集( sdiff )这种集合运算</font>**
  - 也因为它的这种特性, **一般用于集合间聚合计算的场景 -- 比如找出两个用户的共同好友; 查找在群组A但不在群组B的用户**
  - 此外还比较适用于点赞功能、抽奖系统等等



- Zset有序集合: **<font style="color:blue">用于存储"字符串成员"与"浮点数分数"之间的有序映射</font>**, 元素的排列顺序由分数的大小决定
  - 适用于排行榜这种需要排序的场景

> `ZRANGE key 0 -1` -- 默认是从小到大排序的, 想降序可以用: `ZREVRANGE key 0 -1`

# Redis的持久化机制

Redis提供两种主要的持久化机制: **RDB快照**(Redis DataBase) 和 **AOF日志追加**(Append Only File), 它们各有特点和适用场景:



RDB 快照持久化就是指**<font style="color:blue">在指定的间隔生成内存数据的全量快照, 并将其写入磁盘 (对应 .rdb 文件)</font>**. 

触发方式有两种: 

- 自动触发: **通过配置 save 参数**设置触发快照的条件, 例如 `save 900 1` 表示: **<font style="color:blue">如果 Redis 自上一次快照以来</font>, 过去了900秒**, 且至少发生了1次写操作, 就会触发快照
  - **<font style="color:blue">触发快照后当前时间会被记为新的"上次快照时间", 写操作计数被清零</font>**
  - **当配置了多个 `save m n` 这种命令时, <font style="color:blue">满足任意一个条件都会触发持久化</font>**. 且任意一条 save 条件被触发了, 所有的 save 条件都会一并重置计时器和写操作计数器
  - **<font style="color:blue">自动触发实际执行的是 bgsave 命令</font>**
- 手动触发: 有 save 和 bgsave 两种方式. 更推荐使用 bgsave
  - **因为 save 命令会阻塞 Redis 主线程, 导致服务不可用**
  - **而 bgsave 是从主线程中 Fork 一个子进程异步执行快照操作(Fork 过程 Redis 是阻塞的), 但随后 Redis 就可以继续正常处理客户端请求**

优点: **因为 RDB 文件是二进制格式, 文件体积小, 适合备份和恢复**. **<font style="color:blue">恢复数据时直接加载 RDB 文件, 速度比 AOF 快</font>**. 另外使用 bgsave 异步生成快照对 Redis 的性能影响较小

缺点: **数据丢失风险 -- 如果 Redis 崩溃, 最后一次快照之后的数据就会丢失**; 另外**因为快照是定期生成的, 所以无法做到实时持久化**

> 常见配置项:
>
> **RDB文件名: dbfilename dump.rdb**, 默认 RDB 快照的文件名就是 dump.rdb
>
> **RDB文件目录: dir <具体目录>** -- 快照最终保存位置: `dir` + `/` + `dbfilename`
>
> `rdbchecksum yes`: 在存储快照后, 还可以让 Redis 使用 CRC64 算法来进行数据校验, 但是这样做会增加大**约 10% 的性能消耗, 如果希望获取到最大的性能提升, 可以关闭此功能**



AOF (日志持久化): 每次写操作都会以日志形式追加到 .aof 文件中, **默认 AOF 持久化机制是关闭的, <font style="color:blue">需要在 Redis 的配置文件中配置 `appendonly yes` (但 Redis 6.0 版本之后默认就是开启的了)</font>**

**此外可以通过配置 appendfsync 参数来控制 AOF 文件的同步频率: (刷盘时机)**

- Always: 每次写操作都同步到磁盘, 这样做数据最安全, 但性能最低
- Everysec: 表示每次写操作命令执行完后, 先将命令写入到 AOF 文件的内核缓冲区, **<font style="color:blue">然后每隔一秒将缓冲区中的内容写回到磁盘</font>**. 兼顾了性能与数据安全 **(默认配置)**
- **No: 由操作系统决定同步时机**, 完全依赖 OS 的缓存. 性能最高, 但数据安全性最低

**<font style="color:blue">其次 AOF 文件随着写操作的不断增多, 体积越来越大, 所以需要对 AOF 文件进行重写来缩小体积</font>**

比如有这样几点策略: 过期的数据不在写入文件; 无效的命令不再写入文件 (比如重复设值); 还可以合并命令 (比如多个 set 合并成一个 mset). [重写时不会丢失数据, 因为新旧 AOF 文件会**并行维护**, 保证安全性]

>实现机制: 先 Fork 创建子进程 -- 子进程遍历当前内存快照, 生成一套新的 AOF 文件(其中只包含必要命令) -- 主进程继续接收请求并记录增量操作 -- 重写完成后, 主进程将增量操作追加上去, 然后以原子方式替换掉旧的 AOF 文件 [以确保最终 AOF 文件是 "内存快照 + 全部重写期间的新操作" 的完整合集]
>
>增量操作就是发生在 AOF 重写过程中的写操作, 因为子进程无法感知所以必须由主进程记录下来

重写触发可以分成两种方式: 

```markdown
- 主动触发: 调用 `bgrewriteaof` 命令
- 被动触发: 通过两个配置参数管理
`auto-aof-rewrite-percentage 100` -- 表示 AOF 文件大小超过上次重写后文件大小的百分比时
`auto-aof-rewrite-min-size 64mb` -- 表示 AOF 文件大小超过指定值时
**只有当这两个条件同时满足了, 才会自动触发 AOF 重写**
```

优点: 因为数据同步频率比较快, **<font style="color:blue">所以提供了更好的数据安全性</font>, 即使 Redis 服务器宕机也只会丢失最后一次写入前的数据**, 并且 AOF 也支持多种同步策略, 可以根据实际需求进行调整来平衡数据安全性和性能

缺点: **因为记录了每一个写操作, <font style="color:blue">所以 AOF 文件通常比 RDB 文件更大, 消耗更多磁盘空间</font>**. 另外频繁的 IO 操作 (尤其是同步策略设置为 Always 时), 可能会对 Redis 的写入性能造成一定影响

> 常见配置项:
>
> appendfilename "appendonly.aof" -- AOF 文件名称
>
> dir /var/lib/redis -- AOF 文件存储路径

**<font style="color:blue">如果同时开启了 RDB 和 AOF 持久化, 会优先使用 AOF 文件来还原数据</font>**



RDB + AOF 混合持久化: **结合了 RDB 和 AOF 的优点, 既能快速加载又能避免丢失过多的数据**

开启混合持久化方式的设置: `aof-use-rdb-preamble yes`, 默认其实就是 yes, 设置为 no 即为禁用. 这种方式就是 RDB 快照负责做全量持久化, AOF 做增量持久化:

**当前数据以 RDB 格式保存, 新的命令以 AOF 格式保存. <font style="color:blue">混合持久化在 AOF 重写时, 首先将当前数据以 RDB 的格式写入到新 AOF 文件的开始位置, 如果有新的命令会追加到文件末尾</font>**

这样重启服务的时候会从 RDB 和 AOF 两部分恢复数据, 既保证了数据完整性, 又提高了恢复数据的性能

混合持久化机制是 Redis 4.0 引入的新特性. 因为**<font style="color:blue">自 4.0 版本起, AOF 重写时可以在 AOF 文件前插入一段 RDB 快照</font>**作为"起点", 之后再追加新的写操作命令



































